{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAEL7be5XU3X"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from IPython.display import display, Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Paths and directory setup\n",
        "# -----------------------------\n",
        "BASE = '/content'\n",
        "# Original uploaded folders (as the user said they will be uploaded directly under /content)\n",
        "orig_undamaged_train = os.path.join(BASE, 'Undamaged Plates Train')\n",
        "orig_damaged_train = os.path.join(BASE, 'Damaged Plates Train')\n",
        "orig_undamaged_test = os.path.join(BASE, 'Undamaged Plates Test')\n",
        "orig_damaged_test = os.path.join(BASE, 'Damaged Plates Test')\n",
        "\n",
        "\n",
        "# Working structure for Keras ImageDataGenerator\n",
        "DATA_DIR = os.path.join(BASE, 'plate_data')\n",
        "train_dir = os.path.join(DATA_DIR, 'train')\n",
        "test_dir = os.path.join(DATA_DIR, 'test')\n",
        "\n",
        "\n",
        "# helper to create directories and copy files\n",
        "def prepare_dir(src, dst):\n",
        "    os.makedirs(dst, exist_ok=True)\n",
        "    if os.path.isdir(src):\n",
        "        files = glob.glob(os.path.join(src, '*'))\n",
        "        for f in files:\n",
        "            if os.path.isfile(f):\n",
        "                shutil.copy(f, dst)\n",
        "    else:\n",
        "        print(f\"Warning: source folder not found: {src}\")\n",
        "\n",
        "\n",
        "# create class subfolders: 'undamaged' and 'damaged'\n",
        "prepare_dir(orig_undamaged_train, os.path.join(train_dir, 'undamaged'))\n",
        "prepare_dir(orig_damaged_train, os.path.join(train_dir, 'damaged'))\n",
        "prepare_dir(orig_undamaged_test, os.path.join(test_dir, 'undamaged'))\n",
        "prepare_dir(orig_damaged_test, os.path.join(test_dir, 'damaged'))\n",
        "\n",
        "\n",
        "print('Train folder counts:')\n",
        "print('undamaged:', len(os.listdir(os.path.join(train_dir, 'undamaged'))))\n",
        "print('damaged:', len(os.listdir(os.path.join(train_dir, 'damaged'))))\n",
        "print('Test folder counts:')\n",
        "print('undamaged:', len(os.listdir(os.path.join(test_dir, 'undamaged'))))\n",
        "print('damaged:', len(os.listdir(os.path.join(test_dir, 'damaged'))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yr93neM7YjIE",
        "outputId": "73b9f243-6d5e-4130-b83c-c1a2090b46a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train folder counts:\n",
            "undamaged: 147\n",
            "damaged: 105\n",
            "Test folder counts:\n",
            "undamaged: 23\n",
            "damaged: 24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Image data pipeline\n",
        "# -----------------------------\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH = 16\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "rotation_range=15,\n",
        "width_shift_range=0.1,\n",
        "height_shift_range=0.1,\n",
        "shear_range=0.05,\n",
        "zoom_range=0.1,\n",
        "horizontal_flip=True,\n",
        "validation_split=0.15)\n",
        "\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "train_dir,\n",
        "target_size=IMG_SIZE,\n",
        "batch_size=BATCH,\n",
        "class_mode='binary',\n",
        "subset='training')\n",
        "\n",
        "\n",
        "val_generator = train_datagen.flow_from_directory(\n",
        "train_dir,\n",
        "target_size=IMG_SIZE,\n",
        "batch_size=BATCH,\n",
        "class_mode='binary',\n",
        "subset='validation')\n",
        "\n",
        "\n",
        "# test generator\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "test_dir,\n",
        "target_size=IMG_SIZE,\n",
        "batch_size=1,\n",
        "class_mode='binary',\n",
        "shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ha32cyxY0SN",
        "outputId": "8aa04db0-fd6a-4f5d-dcd4-6d77942198da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 215 images belonging to 2 classes.\n",
            "Found 37 images belonging to 2 classes.\n",
            "Found 47 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Build a simple CNN\n",
        "# -----------------------------\n",
        "def build_cnn(input_shape=(*IMG_SIZE, 3)):\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=input_shape),\n",
        "        layers.Conv2D(32, (3,3), activation='relu'),\n",
        "        layers.MaxPooling2D((2,2)),\n",
        "        layers.Conv2D(64, (3,3), activation='relu'),\n",
        "        layers.MaxPooling2D((2,2)),\n",
        "        layers.Conv2D(128, (3,3), activation='relu'),\n",
        "        layers.MaxPooling2D((2,2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "cnn_model = build_cnn()\n",
        "cnn_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "3xaqYX8hY8uh",
        "outputId": "bbbb8bd9-e23b-4127-c86f-595788d27bd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_9 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_10 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_11 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m86528\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m86528\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │    \u001b[38;5;34m11,075,712\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">86528</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">86528</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">11,075,712</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,169,089\u001b[0m (42.61 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,169,089</span> (42.61 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,169,089\u001b[0m (42.61 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,169,089</span> (42.61 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Train CNN\n",
        "# -----------------------------\n",
        "EPOCHS = 12\n",
        "history = cnn_model.fit(\n",
        "train_generator,\n",
        "validation_data=val_generator,\n",
        "epochs=EPOCHS\n",
        ")\n",
        "\n",
        "\n",
        "# save the cnn model\n",
        "cnn_model.save('/content/plate_cnn_model.h5')\n",
        "print('Saved CNN model to /content/plate_cnn_model.h5')\n",
        "best_val_acc = max(history.history['val_accuracy'])\n",
        "print(f\"Best Validation Accuracy: {best_val_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h55tObQWZBw7",
        "outputId": "6bfe0076-9325-4eeb-c1f2-f4d842b26293"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 489ms/step - accuracy: 0.5715 - loss: 1.6155 - val_accuracy: 0.5946 - val_loss: 0.6417\n",
            "Epoch 2/12\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 396ms/step - accuracy: 0.6752 - loss: 0.6207 - val_accuracy: 0.8378 - val_loss: 0.3583\n",
            "Epoch 3/12\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.8504 - loss: 0.5118 - val_accuracy: 0.8378 - val_loss: 0.3482\n",
            "Epoch 4/12\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 329ms/step - accuracy: 0.8354 - loss: 0.3805 - val_accuracy: 0.7297 - val_loss: 0.3843\n",
            "Epoch 5/12\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 274ms/step - accuracy: 0.9084 - loss: 0.2597 - val_accuracy: 0.8378 - val_loss: 0.2949\n",
            "Epoch 6/12\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 277ms/step - accuracy: 0.8891 - loss: 0.2384 - val_accuracy: 0.7568 - val_loss: 0.4620\n",
            "Epoch 7/12\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 336ms/step - accuracy: 0.9110 - loss: 0.2212 - val_accuracy: 0.9459 - val_loss: 0.3053\n",
            "Epoch 8/12\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - accuracy: 0.9238 - loss: 0.2138 - val_accuracy: 0.7838 - val_loss: 0.3866\n",
            "Epoch 9/12\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 274ms/step - accuracy: 0.8732 - loss: 0.2513 - val_accuracy: 0.8649 - val_loss: 0.2887\n",
            "Epoch 10/12\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 430ms/step - accuracy: 0.8773 - loss: 0.2213 - val_accuracy: 0.8108 - val_loss: 0.2830\n",
            "Epoch 11/12\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 276ms/step - accuracy: 0.9156 - loss: 0.2004 - val_accuracy: 0.7568 - val_loss: 0.3295\n",
            "Epoch 12/12\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.9162 - loss: 0.2243 - val_accuracy: 0.7838 - val_loss: 0.3521\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved CNN model to /content/plate_cnn_model.h5\n",
            "Best Validation Accuracy: 0.9459\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. NLP model (sentiment) -- single mixed CSV with labels\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import layers, models\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "# ---- CONFIG ----\n",
        "CSV_PATH = '/content/plate_reviews_10000.csv'  # one file with columns: review_text,label\n",
        "MAX_WORDS = 10000\n",
        "MAX_LEN = 120\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# ---- LOAD MIXED CSV ----\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "df = df[['review_text','label']].dropna()\n",
        "texts = df['review_text'].astype(str).tolist()\n",
        "labels = df['label'].astype(int).values\n",
        "\n",
        "# ---- SPLIT ----\n",
        "X_train_text, X_val_text, y_train_text, y_val_text = train_test_split(\n",
        "    texts, labels, test_size=0.15, random_state=42, stratify=labels\n",
        ")\n",
        "\n",
        "# ---- TOKENIZE ----\n",
        "tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(X_train_text)\n",
        "\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train_text)\n",
        "X_val_seq   = tokenizer.texts_to_sequences(X_val_text)\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_LEN, padding='post')\n",
        "X_val_pad   = pad_sequences(X_val_seq,   maxlen=MAX_LEN, padding='post')\n",
        "\n",
        "# ---- MODEL ----\n",
        "nlp_model = models.Sequential([\n",
        "    layers.Input(shape=(MAX_LEN,)),\n",
        "    layers.Embedding(MAX_WORDS, 64),\n",
        "    layers.Bidirectional(layers.LSTM(64)),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "nlp_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "nlp_model.summary()\n",
        "\n",
        "# Optional: early stopping\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
        "\n",
        "# ---- TRAIN ----\n",
        "nlp_history = nlp_model.fit(\n",
        "    X_train_pad, y_train_text,\n",
        "    validation_data=(X_val_pad, y_val_text),\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    callbacks=[early_stop]\n",
        ")\n",
        "\n",
        "# ---- SAVE MODEL & TOKENIZER ----\n",
        "nlp_model.save('/content/plate_nlp_model.h5')\n",
        "with open('/content/plate_tokenizer.pkl', 'wb') as f:\n",
        "    pickle.dump({'tokenizer': tokenizer, 'max_len': MAX_LEN}, f)\n",
        "\n",
        "print('Saved NLP model to /content/plate_nlp_model.h5')\n",
        "print('Saved tokenizer to /content/plate_tokenizer.pkl')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "id": "VmKWDvm0clMN",
        "outputId": "d161efba-0460-403d-9977-63056111b5b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │       \u001b[38;5;34m640,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m66,048\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">640,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m714,369\u001b[0m (2.73 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">714,369</span> (2.73 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m714,369\u001b[0m (2.73 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">714,369</span> (2.73 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.7792 - loss: 0.4350 - val_accuracy: 0.9607 - val_loss: 0.0836\n",
            "Epoch 2/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9476 - loss: 0.1059 - val_accuracy: 0.9607 - val_loss: 0.0680\n",
            "Epoch 3/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.9569 - loss: 0.0720 - val_accuracy: 0.9627 - val_loss: 0.0635\n",
            "Epoch 4/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9596 - loss: 0.0665 - val_accuracy: 0.9607 - val_loss: 0.0671\n",
            "Epoch 5/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.9580 - loss: 0.0679 - val_accuracy: 0.9627 - val_loss: 0.0565\n",
            "Epoch 6/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.9578 - loss: 0.0690 - val_accuracy: 0.9640 - val_loss: 0.0546\n",
            "Epoch 7/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9554 - loss: 0.0903 - val_accuracy: 0.9507 - val_loss: 0.0817\n",
            "Epoch 8/10\n",
            "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9522 - loss: 0.0899 - val_accuracy: 0.9580 - val_loss: 0.0669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved NLP model to /content/plate_nlp_model.h5\n",
            "Saved tokenizer to /content/plate_tokenizer.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Real-time simulation in Colab: show an image, get a comment, evaluate\n",
        "# -----------------------------------------------------------------------\n",
        "import os, glob, random\n",
        "from IPython.display import display, Image as IPyImage\n",
        "from PIL import Image as PILImage  # keep PIL separate to avoid name clash\n",
        "import numpy as np\n",
        "\n",
        "print('\\n--- Real-time demonstration ---')\n",
        "\n",
        "# Prefer using the generator file list if available (ensures same preprocessing structure)\n",
        "all_test_images = []\n",
        "try:\n",
        "    all_test_images = getattr(test_generator, 'filepaths', [])\n",
        "except NameError:\n",
        "    pass  # test_generator may not exist in this runtime\n",
        "\n",
        "# Fallback: search the filesystem\n",
        "def find_images(root):\n",
        "    patterns = [\n",
        "        os.path.join(root, '*', '*'),  # test_dir/<class>/<image>\n",
        "        os.path.join(root, '*')        # test_dir/<image>\n",
        "    ]\n",
        "    paths = []\n",
        "    for p in patterns:\n",
        "        paths.extend(glob.glob(p))\n",
        "    # keep only images\n",
        "    exts = ('.png', '.jpg', '.jpeg', '.bmp', '.gif', '.webp')\n",
        "    paths = [p for p in paths if p.lower().endswith(exts)]\n",
        "    # de-dup\n",
        "    return sorted(list(set(paths)))\n",
        "\n",
        "if not all_test_images:\n",
        "    # Ensure test_dir exists\n",
        "    try:\n",
        "        assert os.path.isdir(test_dir), f\"test_dir does not exist: {test_dir}\"\n",
        "    except NameError:\n",
        "        raise RuntimeError(\"Variable 'test_dir' is not defined. Set it to your test images folder.\")\n",
        "    all_test_images = find_images(test_dir)\n",
        "\n",
        "if len(all_test_images) == 0:\n",
        "    raise RuntimeError('No test images found. Check upload, folder names, and that images are under test_dir.')\n",
        "\n",
        "sample_img_path = random.choice(all_test_images)\n",
        "print('Displaying test image:', sample_img_path)\n",
        "\n",
        "# Use IPython display (NOT PIL) to render in Colab output\n",
        "display(IPyImage(filename=sample_img_path, width=400))\n",
        "\n",
        "# Predict image class\n",
        "from tensorflow.keras.preprocessing import image as kimage\n",
        "\n",
        "img = kimage.load_img(sample_img_path, target_size=IMG_SIZE)\n",
        "img_arr = kimage.img_to_array(img) / 255.0\n",
        "img_input = np.expand_dims(img_arr, axis=0)\n",
        "img_pred_prob = cnn_model.predict(img_input, verbose=0)[0][0]\n",
        "\n",
        "# Retrieve class mapping safely\n",
        "try:\n",
        "    class_map = train_generator.class_indices\n",
        "except NameError:\n",
        "    # If the generator is not available, define manually (adjust if different)\n",
        "    # Example default:\n",
        "    class_map = {'damaged': 0, 'undamaged': 1}\n",
        "print('Class mapping:', class_map)\n",
        "\n",
        "# Determine predicted label from threshold and mapping\n",
        "pred_index = int(img_pred_prob >= 0.5)\n",
        "inv_map = {v: k for k, v in class_map.items()}\n",
        "predicted_label_name = inv_map.get(pred_index, 'unknown')\n",
        "\n",
        "print(f'Image predicted as: {predicted_label_name} (prob={img_pred_prob:.3f})')\n",
        "print(f'This is a {predicted_label_name.upper()} plate.')\n",
        "\n",
        "# --- Real-time sentiment on user's typed comment (uses your saved tokenizer/model if needed) ---\n",
        "import pickle\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def load_nlp_components(model_path='/content/plate_nlp_model.h5', tok_path='/content/plate_tokenizer.pkl'):\n",
        "    global nlp_model, tokenizer, MAX_LEN\n",
        "    try:\n",
        "        _ = nlp_model; _ = tokenizer; _ = MAX_LEN\n",
        "    except NameError:\n",
        "        nlp_model = load_model(model_path)\n",
        "        with open(tok_path, 'rb') as f:\n",
        "            payload = pickle.load(f)\n",
        "        tokenizer = payload['tokenizer']\n",
        "        MAX_LEN = payload['max_len']\n",
        "    return nlp_model, tokenizer, MAX_LEN\n",
        "\n",
        "def predict_sentiment_label(text):\n",
        "    nlp_model, tokenizer, MAX_LEN = load_nlp_components()\n",
        "    seq = tokenizer.texts_to_sequences([text])\n",
        "    pad = pad_sequences(seq, maxlen=MAX_LEN, padding='post')\n",
        "    prob = nlp_model.predict(pad, verbose=0)[0][0]\n",
        "    return ('positive' if prob >= 0.5 else 'negative', float(prob))\n",
        "\n",
        "print('\\nPlease type your comment about the displayed plate and press Enter:')\n",
        "user_comment = input().strip()\n",
        "if user_comment == '':\n",
        "    user_comment = 'No comment provided.'\n",
        "\n",
        "sent_label, sent_prob = predict_sentiment_label(user_comment)\n",
        "print(f'Comment sentiment predicted: {sent_label} (prob={sent_prob:.3f})')\n",
        "\n",
        "# Overall experience logic\n",
        "if sent_label == 'positive' and predicted_label_name == 'damaged':\n",
        "    print(\"Overall Negative Experience\")\n",
        "elif sent_label == 'negative' and predicted_label_name == 'damaged':\n",
        "    print(\"Overall Negative Experience\")\n",
        "elif sent_label == 'negative' and predicted_label_name == 'undamaged':\n",
        "    print(\"Overall Negative Experience\")\n",
        "else:\n",
        "    print(\"Overall Positive Experience\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "id": "TOQjOlGCc8Bs",
        "outputId": "55d284a5-a71b-4e42-8579-8791658df6ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Real-time demonstration ---\n",
            "Displaying test image: /content/plate_data/test/damaged/p198.jpg\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/jpeg": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "image/jpeg": {
              "width": 400
            }
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class mapping: {'damaged': 0, 'undamaged': 1}\n",
            "Image predicted as: damaged (prob=0.496)\n",
            "This is a DAMAGED plate.\n",
            "\n",
            "Please type your comment about the displayed plate and press Enter:\n",
            "Amazing plate\n",
            "Comment sentiment predicted: positive (prob=0.992)\n",
            "Overall Negative Experience\n"
          ]
        }
      ]
    }
  ]
}